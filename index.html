<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Beat Edit Generator</title>
  <style>
    body {
      background: #0e0e0e;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
    }
    canvas {
      margin-top: 20px;
      border: 2px solid #333;
      background: black;
    }
    input, button {
      margin: 10px;
      padding: 10px;
      font-size: 16px;
    }
  </style>
</head>
<body>
  <h1>ðŸŽ¬ GÃ©nÃ©rateur d'Edit CapCut</h1>
  <p>Importe une musique (.mp3) et des images, puis clique sur "Preview".</p>
  <input type="file" id="audioInput" accept="audio/*"><br>
  <input type="file" id="imageInput" accept="image/*" multiple><br>
  <button id="preview">Preview</button>
  <button id="export">Exporter la vidÃ©o</button><br>
  <canvas id="canvas" width="640" height="360"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.11.6/dist/ffmpeg.min.js"></script>
<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const audioInput = document.getElementById('audioInput');
const imageInput = document.getElementById('imageInput');
const previewBtn = document.getElementById('preview');
const exportBtn = document.getElementById('export');

let audioContext = new AudioContext();
let images = [], audioBuffer, beats = [], frames = [];

function log(msg) { console.log('[INFO]', msg); }

async function loadImages(files) {
  return Promise.all([...files].map(file => {
    return new Promise(resolve => {
      const img = new Image();
      img.onload = () => resolve(img);
      img.src = URL.createObjectURL(file);
    });
  }));
}

async function detectBeats(buffer) {
  const raw = buffer.getChannelData(0);
  const threshold = 0.27;
  const beats = [];
  let i = 0;
  while (i < raw.length) {
    if (Math.abs(raw[i]) > threshold) {
      beats.push(i / buffer.sampleRate);
      i += 22000;
    }
    i++;
  }
  return beats;
}

function drawFrame(img, scale, angle, flash, shakeX) {
  const w = canvas.width;
  const h = canvas.height;

  ctx.save();
  ctx.clearRect(0, 0, w, h);
  ctx.translate(w / 2 + shakeX, h / 2);
  ctx.rotate(angle);
  ctx.scale(scale, scale);

  const ratio = Math.min(w / img.width, h / img.height);
  const iw = img.width * ratio;
  const ih = img.height * ratio;

  ctx.drawImage(img, -iw / 2, -ih / 2, iw, ih);
  ctx.restore();

  if (flash) {
    ctx.fillStyle = 'rgba(255,255,255,0.25)';
    ctx.fillRect(0, 0, w, h);
  }
}

async function generatePreview() {
  if (!audioInput.files[0] || imageInput.files.length === 0) {
    alert("Ajoute un MP3 et au moins une image.");
    return;
  }

  const audioData = await audioInput.files[0].arrayBuffer();
  audioBuffer = await audioContext.decodeAudioData(audioData);
  images = await loadImages(imageInput.files);
  beats = await detectBeats(audioBuffer);

  const duration = audioBuffer.duration;
  const fps = 30;
  const totalFrames = Math.floor(duration * fps);
  const beatFrames = beats.map(t => Math.floor(t * fps));

  frames = [];
  let currentImg = 0;

  // ðŸ”Š Lecture audio synchronisÃ©e
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);
  source.start();

  for (let f = 0; f < totalFrames; f++) {
    if (beatFrames.includes(f)) {
      currentImg = (currentImg + 1) % images.length;
    }

    const beatOffset = beatFrames.find(b => b >= f) - f || 0;
    const scale = 1 + (beatOffset === 0 ? 0.5 : 0.1 * Math.exp(-Math.abs(beatOffset) / 3));
    const angle = beatOffset === 0 ? (Math.random() - 0.5) * 0.2 : 0;
    const shakeX = beatOffset === 0 ? (Math.random() - 0.5) * 20 : 0;
    const flash = beatOffset === 0;

    drawFrame(images[currentImg], scale, angle, flash, shakeX);

    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    frames.push(imageData);

    await new Promise(r => setTimeout(r, 1000 / fps));
  }

  alert("âœ… Preview terminÃ©e ! Clique sur Exporter.");
}

async function exportVideo() {
  const { createFFmpeg, fetchFile } = FFmpeg;
  const ffmpeg = createFFmpeg({ log: true });
  await ffmpeg.load();

  const fps = 30;
  const width = canvas.width;
  const height = canvas.height;

  for (let i = 0; i < frames.length; i++) {
    const off = new OffscreenCanvas(width, height);
    const ctx2 = off.getContext('2d');
    ctx2.putImageData(frames[i], 0, 0);
    const blob = await off.convertToBlob({ type: 'image/png' });
    ffmpeg.FS('writeFile', `frame_${String(i).padStart(4, '0')}.png`, await fetchFile(blob));
  }

  ffmpeg.FS('writeFile', 'audio.mp3', await fetchFile(audioInput.files[0]));

  await ffmpeg.run(
    '-framerate', `${fps}`,
    '-i', 'frame_%04d.png',
    '-i', 'audio.mp3',
    '-c:v', 'libvpx-vp9',
    '-c:a', 'libvorbis',
    '-pix_fmt', 'yuv420p',
    '-shortest',
    'output.webm'
  );

  const data = ffmpeg.FS('readFile', 'output.webm');
  const url = URL.createObjectURL(new Blob([data.buffer], { type: 'video/webm' }));
  const a = document.createElement('a');
  a.href = url;
  a.download = 'edit.webm';
  a.click();
}

previewBtn.onclick = generatePreview;
exportBtn.onclick = exportVideo;
</script>
</body>
</html>
