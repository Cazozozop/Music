<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>G√©n√©rateur d'Edit CapCut</title>
  <style>
    body {
      background: #0e0e0e;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
    }
    canvas {
      margin-top: 20px;
      border: 2px solid #333;
      background: black;
    }
    input, button {
      margin: 10px;
      padding: 10px;
      font-size: 16px;
    }
  </style>
</head>
<body>
  <h1>üé• G√©n√©rateur d'Edit CapCut</h1>
  <p>Importe un MP3 et des images ou une vid√©o.</p>
  <input type="file" id="audioInput" accept="audio/*"><br>
  <input type="file" id="visualInput" accept="image/*,video/*" multiple><br>
  <button id="preview">Preview</button>
  <button id="export">Exporter la vid√©o</button><br>
  <canvas id="canvas" width="640" height="360"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.11.6/dist/ffmpeg.min.js"></script>
<script>
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const audioInput = document.getElementById('audioInput');
const visualInput = document.getElementById('visualInput');
const previewBtn = document.getElementById('preview');
const exportBtn = document.getElementById('export');

let audioContext = new AudioContext();
let visualElements = [], audioBuffer, beats = [], frames = [];
let isVideo = false, videoElement;

function loadMedia(files) {
  const fileList = [...files];
  const videoFile = fileList.find(f => f.type.startsWith('video/'));
  if (videoFile) {
    isVideo = true;
    return new Promise(resolve => {
      videoElement = document.createElement('video');
      videoElement.src = URL.createObjectURL(videoFile);
      videoElement.crossOrigin = 'anonymous';
      videoElement.onloadeddata = () => resolve([videoElement]);
    });
  } else {
    isVideo = false;
    return Promise.all(fileList.map(file => {
      return new Promise(resolve => {
        const img = new Image();
        img.onload = () => resolve(img);
        img.src = URL.createObjectURL(file);
      });
    }));
  }
}

async function detectBeats(buffer) {
  const raw = buffer.getChannelData(0);
  const threshold = 0.25;
  const beats = [];
  let i = 0;
  while (i < raw.length) {
    const energy = Math.abs(raw[i]);
    if (energy > threshold) {
      beats.push({
        time: i / buffer.sampleRate,
        intensity: Math.min(1, energy * 4)
      });
      i += 20000;
    } else {
      i++;
    }
  }
  return beats;
}

function drawVisual(el, scale, angle, flash, shakeX) {
  const w = canvas.width;
  const h = canvas.height;
  ctx.save();
  ctx.clearRect(0, 0, w, h);
  ctx.translate(w / 2 + shakeX, h / 2);
  ctx.rotate(angle);
  ctx.scale(scale, scale);

  const ratio = Math.min(w / el.videoWidth || el.width, h / el.videoHeight || el.height);
  const iw = (el.videoWidth || el.width) * ratio;
  const ih = (el.videoHeight || el.height) * ratio;

  ctx.drawImage(el, -iw / 2, -ih / 2, iw, ih);
  ctx.restore();

  if (flash) {
    ctx.fillStyle = 'rgba(255,255,255,0.2)';
    ctx.fillRect(0, 0, w, h);
  }
}

async function generatePreview() {
  if (!audioInput.files[0] || visualInput.files.length === 0) {
    alert("Ajoute un MP3 et au moins une image ou vid√©o.");
    return;
  }

  const audioData = await audioInput.files[0].arrayBuffer();
  audioBuffer = await audioContext.decodeAudioData(audioData);
  visualElements = await loadMedia(visualInput.files);
  beats = await detectBeats(audioBuffer);

  const duration = audioBuffer.duration;
  const fps = 30;
  const totalFrames = Math.floor(duration * fps);

  const beatFrames = beats.map(b => ({ frame: Math.floor(b.time * fps), intensity: b.intensity }));
  const beatMap = {};
  beatFrames.forEach(b => beatMap[b.frame] = b.intensity);

  // Play audio in sync
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);
  source.start();

  if (isVideo) videoElement.play();

  let currentImg = 0;
  for (let f = 0; f < totalFrames; f++) {
    const beat = beatMap[f] || 0;
    const decay = Math.exp(-((f % fps) / 8));
    const intensity = beat * decay;

    const scale = 1 + intensity * 0.4;
    const angle = (Math.random() - 0.5) * 0.1 * intensity;
    const shakeX = (Math.random() - 0.5) * 20 * intensity;
    const flash = intensity > 0.2;

    if (!isVideo) currentImg = (f % (visualElements.length * 15)) / 15 | 0;
    const visual = isVideo ? videoElement : visualElements[currentImg];

    drawVisual(visual, scale, angle, flash, shakeX);
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    frames.push(imageData);

    await new Promise(r => setTimeout(r, 1000 / fps));
  }
  alert("Preview termin√©e ! Clique sur Exporter.");
}

async function exportVideo() {
  const { createFFmpeg, fetchFile } = FFmpeg;
  const ffmpeg = createFFmpeg({ log: true });
  await ffmpeg.load();

  const fps = 30;
  const width = canvas.width;
  const height = canvas.height;

  for (let i = 0; i < frames.length; i++) {
    const off = new OffscreenCanvas(width, height);
    const ctx2 = off.getContext('2d');
    ctx2.putImageData(frames[i], 0, 0);
    const blob = await off.convertToBlob({ type: 'image/png' });
    ffmpeg.FS('writeFile', `frame_${String(i).padStart(4, '0')}.png`, await fetchFile(blob));
  }

  ffmpeg.FS('writeFile', 'audio.mp3', await fetchFile(audioInput.files[0]));
  await ffmpeg.run(
    '-framerate', `${fps}`,
    '-i', 'frame_%04d.png',
    '-i', 'audio.mp3',
    '-c:v', 'libvpx-vp9',
    '-c:a', 'libvorbis',
    '-pix_fmt', 'yuv420p',
    '-shortest',
    'output.webm'
  );
  const data = ffmpeg.FS('readFile', 'output.webm');
  const url = URL.createObjectURL(new Blob([data.buffer], { type: 'video/webm' }));
  const a = document.createElement('a');
  a.href = url;
  a.download = 'edit.webm';
  a.click();
}

previewBtn.onclick = generatePreview;
exportBtn.onclick = exportVideo;
</script>
</body>
</html>
